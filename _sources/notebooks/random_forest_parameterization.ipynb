{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "In this notebook we present some basic application of random forest to\n",
    "the parameterization of the L96 model previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import L96_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import deque\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from L96_model import RK4, L96_eq1_xdot\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script parameters\n",
    "K = 8\n",
    "J = 32\n",
    "FORCING = 18\n",
    "dt = 0.01\n",
    "T_SPINUP = 50\n",
    "T_SIMULATIONS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = L96_model.L96(K, J, F=FORCING)\n",
    "# First run for spin up\n",
    "model.run(dt, T_SPINUP, store=True)\n",
    "# The data from the run below will be used both for offline training and testing\n",
    "X_history, Y_history, t, closure = model.run(\n",
    "    dt, T_SIMULATIONS, store=True, return_coupling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the quantity below in our online test\n",
    "var_X = X_history.var()\n",
    "var_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scatter-plot of subgrid tendency vs large-scale state X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "_ = plt.hist2d(X_history.flatten(), closure.flatten(), bins=50, cmap=\"binary\")\n",
    "plt.xlabel(\"State X\")\n",
    "plt.ylabel(\"Closure\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Starting with a single regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a very simple approach: we use a single value of the state as our feature (i.e. our feature is a scalar), and the subgrid tendency for the same large-scale variable as the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline training / fitting and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closure.shape, X_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the data into training and test. Since the relation between $X_k$ and its associated subgrid tendency is not expected to depend on $k$, we transform the recorded history into a column vector before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, xy_train, xy_test = train_test_split(\n",
    "    X_history.flatten().reshape(-1, 1), closure.flatten(), test_size=0.33, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train has shape: {X_train.shape}\")\n",
    "print(f\"xy_train has shape: {xy_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define our decision tree. For the sake of the example, we limit the number of leaves to 15. Feel free to increase that number and see how the plot below, showing the true and fitted data, changes. In particular, for larger values, we can see that we overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree = tree.DecisionTreeRegressor(max_leaf_nodes=15)\n",
    "single_tree.fit(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the true training data (the large scale state values on the x-axis, and the parameterization value on the y-axis) and the fitted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(X_train, xy_train, \"b*\")\n",
    "plt.plot(X_train, single_tree.predict(X_train), \"r*\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Parameterization\")\n",
    "plt.legend((\"True\", \"Fitted\"), fontsize=7)\n",
    "plt.title(\"Fit of a regression tree with 15 leaves\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, same plot but for the test data. The test data has not been seen during the fitting procedure, so in some sense this is the true test. While we may fit very well the training data, overfitting will result in poor performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(X_test, xy_test, \"b*\")\n",
    "plt.plot(X_test, single_tree.predict(X_test), \"r*\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Parameterization\")\n",
    "plt.legend((\"True\", \"Predicted\"), fontsize=7)\n",
    "plt.title(\"Test of a regression tree with 15 leaves\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the $R^2$ score for both the training data (fit score) and test data.\n",
    "\\begin{equation*}\n",
    "R^2 = 1 - \\frac{\\sum_{i}{(\\hat{S}_i - S_i)^2}}{\\sum_{i}{(S_i - S_\\text{mean})^2}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_score = single_tree.score(X_train, xy_train)\n",
    "test_score = single_tree.score(X_test, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(xy_test[:8000:K])\n",
    "plt.plot(single_tree.predict(X_test)[:8000:K])\n",
    "plt.xlabel(\"time step\")\n",
    "plt.ylabel(r\"$xy_0$\")\n",
    "plt.legend((\"True\", \"Predicted\"), fontsize=7)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate what is meant by overfitting, we will increase the number of leaves, and store the fit loss and test loss for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_leaves = list(map(lambda x: int(np.exp(x / 2)) + 1, range(1, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_scores, test_scores = [], []\n",
    "for nb in nb_leaves:\n",
    "    current_tree = tree.DecisionTreeRegressor(max_leaf_nodes=nb)\n",
    "    current_tree.fit(X_train, xy_train)\n",
    "    fit_scores.append(current_tree.score(X_train, xy_train))\n",
    "    test_scores.append(current_tree.score(X_test, xy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.loglog(nb_leaves, list(fit_scores), \"*\")\n",
    "plt.loglog(nb_leaves, list(test_scores), \"*\")\n",
    "plt.legend((\"fit_score\", \"test_scores\"), fontsize=7)\n",
    "plt.xlabel(\"Number of leaf nodes\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online implementation of the parameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement this as a parameterization for L96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameterization:\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = X.reshape(-1, 1)\n",
    "        return self.predictor.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the GCM class defined by Yani in his notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCM:\n",
    "    def __init__(self, F, parameterization, time_stepping=RK4):\n",
    "        \"\"\"\n",
    "        GCM with paramerization\n",
    "        Args:\n",
    "            F: forcing\n",
    "            parameterization: function that takes parameters and returns a tendency\n",
    "            time_stepping: time stepping method\n",
    "        \"\"\"\n",
    "        self.F = F\n",
    "        self.parameterization = parameterization\n",
    "        self.time_stepping = time_stepping\n",
    "\n",
    "    def rhs(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: state vector\n",
    "        \"\"\"\n",
    "        return L96_eq1_xdot(X, self.F) + self.parameterization(X)\n",
    "\n",
    "    def __call__(self, X0, dt, nt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X0: initial conditions\n",
    "            dt: time increment\n",
    "            nt: number of forward steps to take\n",
    "            param: parameters of our closure\n",
    "        \"\"\"\n",
    "        time, hist, X = (\n",
    "            dt * np.arange(nt + 1),\n",
    "            np.zeros((nt + 1, len(X0))) * np.nan,\n",
    "            X0.copy(),\n",
    "        )\n",
    "        hist[0] = X\n",
    "\n",
    "        for n in range(nt):\n",
    "            X = self.time_stepping(self.rhs, dt, X)\n",
    "            hist[n + 1], time[n + 1] = X, dt * (n + 1)\n",
    "        return hist, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm = GCM(model.F, Parameterization(single_tree))\n",
    "gcm_no_param = GCM(model.F, lambda x: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_test(param, n_runs, n_steps):\n",
    "    simulations = []\n",
    "    gcm = GCM(model.F, param)\n",
    "    for i in range(n_runs):\n",
    "        if i % 10 == 0:\n",
    "            print(\"run \", i)\n",
    "        X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "        X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "        X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)\n",
    "        simulations.append((X_true, X_param))\n",
    "    squared_errors = np.stack(\n",
    "        [((true - sim) ** 2).mean(axis=-1) for true, sim in simulations], axis=0\n",
    "    )\n",
    "    return np.median(squared_errors, axis=0) / var_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm = GCM(model.F, Parameterization(single_tree))\n",
    "gcm_no_param = GCM(model.F, lambda x: 0)\n",
    "X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, X_true[:, 0], label=\"true\")\n",
    "plt.plot(t, X_no_param[:, 0], label=\"GCM without parameterization\")\n",
    "plt.plot(t, X_param[:, 0], label=\"GCM with paramerization\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$X_0$\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we use the global state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_treeV2 = tree.DecisionTreeRegressor(max_leaf_nodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, xy_train, xy_test = train_test_split(\n",
    "    X_history, closure[:, 0], test_size=0.33, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_treeV2.fit(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_treeV2.score(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_treeV2.score(X_test, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(xy_test[:1000])\n",
    "plt.plot(single_treeV2.predict(X_test)[:1000])\n",
    "plt.xlabel(\"time steps\")\n",
    "plt.ylabel(r\"$xy_0$\")\n",
    "plt.legend((\"True\", \"Predicted\"), fontsize=7)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to adapt our parameterization so that it makes use of the homogeneity of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterizationV2:\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = X.reshape(1, K)\n",
    "        new_X = []\n",
    "        for i in range(K):\n",
    "            new_X.append(np.roll(X, -i, axis=-1))\n",
    "        new_X = np.concatenate(new_X, axis=0)\n",
    "        return self.predictor.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm = GCM(model.F, ParameterizationV2(single_treeV2))\n",
    "gcm_no_param = GCM(model.F, lambda x: 0)\n",
    "X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, X_true[:, 0], label=\"true\")\n",
    "plt.plot(t, X_no_param[:, 0], label=\"GCM without parameterization\")\n",
    "plt.plot(t, X_param[:, 0], label=\"GCM with paramerization\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$X_0$\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: ensemble of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a random forest instead of a single decision tree. The idea is simple: to avoid overfitting, one trains several decision trees on the same data.  The prediction of the random forest is then the average prediction of all decision trees within the ensemble.\n",
    "\n",
    "There are two main ways in which the fitted trees within the forest might differ:\n",
    "- the selected features for the splits: at each iteration of the fitting procedure, the algorithm does not consider all features to select the best split, at least not when the number of features is large. Instead, a finite number of features is considered at random. \n",
    "- the data on which they are trained. Below, by setting bootstrap to True and max_samples to 0.5, we specify that each tree within the forest will only be trained on half of the training data\n",
    "\n",
    "Random forest are an efficient way to avoid overfitting compared to using a single tree. However they do come with a computational and memory cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with an ensemble of 10 decision trees\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=50, max_leaf_nodes=300, bootstrap=True, max_samples=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit to the same training data as in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually get the prediction of each tree within the forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predictions = []\n",
    "for est in rf.estimators_:\n",
    "    tree_predictions.append(est.predict(X_test[:1, :]))\n",
    "tree_predictions = np.array(tree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tree_predictions = {tree_predictions.flatten()}\")\n",
    "print(f\"mean of tree_predictions = {tree_predictions.mean()}\")\n",
    "print(f\"prediction on first row = {rf.predict(X_test[:1, :])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train, xy_train), rf.score(X_test, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(xy_test[:1000])\n",
    "plt.plot(rf.predict(X_test)[:1000])\n",
    "plt.xlabel(\"time steps\")\n",
    "plt.ylabel(r\"$xy_0$\")\n",
    "plt.legend((\"True\", \"Predicted\"), fontsize=7)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can test this online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm = GCM(model.F, ParameterizationV2(rf))\n",
    "gcm_no_param = GCM(model.F, lambda x: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, X_true[:, 0], label=\"true\")\n",
    "plt.plot(t, X_no_param[:, 0], label=\"GCM without parameterization\")\n",
    "plt.plot(t, X_param[:, 0], label=\"GCM with paramerization\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$X_0$\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting is a type of machine learning [boosting](https://en.wikipedia.org/wiki/Boosting_(machine_learning)). It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error. The key idea is to set the target outcomes for this next model in order to minimize the error.\n",
    "\n",
    "Further reading [here](https://www.displayr.com/gradient-boosting-the-coolest-kid-on-the-machine-learning-block/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=200)\n",
    "gbr.fit(X_train, xy_train)\n",
    "score_train = gbr.score(X_train, xy_train)\n",
    "score_test = gbr.score(X_test, xy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_train, score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More features: using past state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we further increase the complexity of our approach by incorporating past state into the features used to carry out our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times = 2\n",
    "new_X = X_history.copy()\n",
    "for i in range(n_times - 1):\n",
    "    new_X = np.concatenate((new_X, np.roll(X_history, i + 1, axis=0)), axis=1)\n",
    "new_X = new_X[n_times:]\n",
    "new_closure = closure[n_times:]\n",
    "\n",
    "X_train, X_test, xy_train, xy_test = train_test_split(\n",
    "    new_X, new_closure[:, 0], test_size=0.33, shuffle=False\n",
    ")\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.max_leaf_nodes = 350\n",
    "rf.max_samples = 0.99\n",
    "rf.n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train, xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, xy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we need to adapt the form of the parameterization, here so that it records past values of the state for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameterization:\n",
    "    def __init__(self, predictor, n_times: int = 5):\n",
    "        self.predictor = predictor\n",
    "        self.past_states = deque(maxlen=n_times - 1)\n",
    "        self.n_times = n_times\n",
    "\n",
    "    def __call__(self, X):\n",
    "        X = X.reshape(1, K)\n",
    "        new_X = []\n",
    "        for i in range(K):\n",
    "            new_X.append(np.roll(X, -i, axis=-1))\n",
    "        new_X = np.concatenate(new_X, 0)\n",
    "        shape = new_X.shape\n",
    "        save_X = new_X.copy()\n",
    "        for i in range(self.n_times - 1):\n",
    "            try:\n",
    "                new_X = np.concatenate((new_X, self.past_states[-i - 1]), axis=1)\n",
    "            except IndexError:\n",
    "                new_X = np.concatenate((new_X, np.zeros(shape)), axis=-1)\n",
    "        self.past_states.append(save_X)\n",
    "        return self.predictor.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2000\n",
    "gcm = GCM(model.F, Parameterization(rf, n_times))\n",
    "gcm_no_param = GCM(model.F, lambda x: 0)\n",
    "X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, X_true[:, 0], label=\"true\")\n",
    "plt.plot(t, X_no_param[:, 0], label=\"GCM without parameterization\")\n",
    "plt.plot(t, X_param[:, 0], label=\"GCM with paramerization\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$X_0$\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with NN parameterization (based on Yani's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_ANN, self).__init__()\n",
    "        self.linear1 = nn.Linear(8, 16)  # 8 inputs, 16 neurons for first hidden layer\n",
    "        self.linear2 = nn.Linear(16, 16)  # 16 neurons for second hidden layer\n",
    "        self.linear3 = nn.Linear(16, 8)  # 8 outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = FF.relu(self.linear1(x))\n",
    "        x = FF.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCM_network:\n",
    "    \"\"\"\n",
    "    GCM class including a neural network parameterization in rhs of equation for tendency\n",
    "    Args:\n",
    "        F: forcing\n",
    "        parameterization: function that takes parameters and returns a tendency\n",
    "        time_stepping: time stepping method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, F, network, time_stepping=RK4):\n",
    "        self.F = F\n",
    "        self.network = network\n",
    "        self.time_stepping = time_stepping\n",
    "\n",
    "    def rhs(self, X, param=[0]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: state vector\n",
    "            param: parameters of our closure, unused here but maintained for consistency of interface\n",
    "        \"\"\"\n",
    "        if self.network.linear1.in_features == 1:\n",
    "            X_torch = torch.from_numpy(X).double()\n",
    "            X_torch = torch.unsqueeze(X_torch, 1)\n",
    "        else:\n",
    "            X_torch = torch.from_numpy(np.expand_dims(X, 0)).double()\n",
    "        return L96_eq1_xdot(X, self.F) + np.squeeze(\n",
    "            self.network(X_torch).data.numpy()\n",
    "        )  # Adding NN parameterization\n",
    "\n",
    "    def __call__(self, X0, dt, nt, param=[0]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X0: initial conditions\n",
    "            dt: time increment\n",
    "            nt: number of forward steps to take\n",
    "            param: parameters of our closure\n",
    "        \"\"\"\n",
    "        time, hist, X = (\n",
    "            dt * np.arange(nt + 1),\n",
    "            np.zeros((nt + 1, len(X0))) * np.nan,\n",
    "            X0.copy(),\n",
    "        )\n",
    "        hist[0] = X\n",
    "\n",
    "        for n in range(nt):\n",
    "            X = self.time_stepping(self.rhs, dt, X, param)\n",
    "            hist[n + 1], time[n + 1] = X, dt * (n + 1)\n",
    "        return hist, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "path_load = \"networks/network_3_layers_100_epoches.pth\"\n",
    "nn_3l = Net_ANN().double()\n",
    "nn_3l.load_state_dict(torch.load(path_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2000\n",
    "gcm = GCM(model.F, ParameterizationV2(single_treeV2))\n",
    "gcm_network = GCM_network(model.F, nn_3l)\n",
    "X_param, t = gcm(model.X, model.dt, n_steps)\n",
    "X_network, t = gcm_network(model.X, model.dt, n_steps)\n",
    "X_no_param, t = gcm_no_param(model.X, model.dt, n_steps)\n",
    "X_true, _, _ = model.run(model.dt, n_steps * model.dt, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, X_true[:, 0], label=\"true\")\n",
    "plt.plot(t, X_no_param[:, 0], label=\"GCM without parameterization (tree)\")\n",
    "plt.plot(t, X_param[:, 0], label=\"GCM with paramerization (network)\")\n",
    "plt.legend(fontsize=7)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(r\"$X_0$\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model / model parameters should we go for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Machine Learning approach: validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Machine Learning approach to this problem is to separate the data into three data sets:\n",
    "- training dataset\n",
    "- validation dataset\n",
    "- test dataset\n",
    "\n",
    "Only data from the training dataset is used for fitting. The validation dataset is then used for model selection and hyperparameters tuning: we select the model whose performance on the validation dataset is best.\n",
    "\n",
    "In order to choose hyperparameters, one needs to make a decision on what set of values to try. One approach is to try a grid of values. Another approach is to try random values. This is recommanded when the possible number of hyperparameter combinations is large. Finally Bayesian approaches to this problem are also popular. Further reading on grid search, random search and bayesian approach [here](https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d).\n",
    "\n",
    "Here we shall implement the random approach: for each model, we will define a range of values for each parameter we wish to tune. We will randomly select a combination of parameter values, fit the model to the training dataset, and assess its performance on the validation dataset. The combination of values leading to the best validation score will be retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree_params_dist = {\n",
    "    \"max_leaf_nodes\": list(map(int, 1 + np.exp(np.arange(11)))),\n",
    "}\n",
    "\n",
    "rf_params_dist = {\n",
    "    \"max_leaf_nodes\": list(map(int, 1 + np.exp(np.arange(13)))),\n",
    "    \"n_estimators\": np.arange(1, 10) * 50,\n",
    "}\n",
    "\n",
    "X_train, X_test, xy_train, xy_test = train_test_split(\n",
    "    X_history, closure[:, 0], test_size=0.33\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below are very slow to execute. Uncomment them to perform the parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_single_treeV2 = RandomizedSearchCV(\n",
    "#     single_treeV2, single_tree_params_dist, n_iter=10, verbose=True\n",
    "# )\n",
    "# best_rf = RandomizedSearchCV(rf, rf_params_dist, n_iter=20, verbose=True)\n",
    "\n",
    "# best_single_treeV2.fit(X_train, xy_train)\n",
    "# best_rf.fit(X_train, xy_train)\n",
    "\n",
    "# print(\"single tree\")\n",
    "# print(f\"best score = {best_single_treeV2.best_score_}\")\n",
    "# print(f\"best parameters = {best_single_treeV2.best_params_}\")\n",
    "# print(\"\\nrandom forest\")\n",
    "# print(f\"best score = {best_rf.best_params_}\")\n",
    "# print(f\"best parameters = {best_rf.score(X_test, xy_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
