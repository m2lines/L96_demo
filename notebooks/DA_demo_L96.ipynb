{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a013986b",
   "metadata": {},
   "source": [
    "# Data Assimilation demo in the Lorenz 96 (L96) two time-scale model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c383a2a",
   "metadata": {},
   "source": [
    "# Recap of L96 and notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a10bb",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "{cite}`Lorenz1995` describes a two-time scale dynamical system using two equations which are:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d}{dt} X_k\n",
    "&= - X_{k-1} \\left( X_{k-2} - X_{k+1} \\right) - X_k + F - \\left( \\frac{hc}{b} \\right) \\sum_{j=0}^{J-1} Y_{j,k}\n",
    "\\\\\n",
    "\\frac{d}{dt} Y_{j,k}\n",
    "&= - cbY_{j+1,k} \\left( Y_{j+2,k} - X_{j-1,k} \\right) - c Y_{j,k} + \\frac{hc}{b} X_k\n",
    "\\end{align}\n",
    "\n",
    "where $X_k$, $k=0,\\ldots,K-1$, denotes the _large scale_ with $K$ degrees of freedom. The $k$ index is periodic, meaning $k=K$ is referring to $k=0$, $k=-1$ is referring to $k=K-1$, and so on. The $j$ indices represent a sub-division of each $k$-element denoting that the $J$ $Y$-values are coupled to a single $X$ value. When $(j+1,k)$ refers to a value beyond $J$, it cycles and refers back to the first value $(1,k+1)$. The slow time-scale queation is forced by the parameter $F$, which determines the chaotic behaviour of the system {cite}`Wilks2005`. The overall structure is illustrated in Fig. 1.\n",
    "\n",
    "\n",
    "```{figure} https://www.researchgate.net/publication/319201436/figure/fig1/AS:869115023589376@1584224577926/Visualisation-of-a-two-scale-Lorenz-96-system-with-J-8-and-K-6-Global-scale-values.png\n",
    ":width: 400px\n",
    ":name: l96-equation-figure\n",
    "\n",
    "*Visualisation of a two-scale Lorenz '96 system with J = 8 and K = 6. Global-scale variables ($X_k$) are updated based on neighbouring variables and on the local-scale variables ($Y_{j,k}$) associated with the corresponding global-scale variable. Local-scale variabless are updated based on neighbouring variables and the associated global-scale variable. The neighbourhood topology of both local and global-scale variables is circular. Image from [Exploiting the chaotic behaviour of atmospheric models with reconfigurable architectures - Scientific Figure on ResearchGate.](https://www.researchgate.net/figure/Visualisation-of-a-two-scale-Lorenz-96-system-with-J-8-and-K-6-Global-scale-values_fig1_319201436)*.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66584b6f",
   "metadata": {},
   "source": [
    "# 1. Define variables and functions to use throughout notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81b262-6d04-44d8-9a61-ada0ea0c9acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from L96_model import L96, RK4, L96_2t_xdot_ydot, L96_eq1_xdot, L96s\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3e7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # fmt: off\n",
    "    K = 40                              # Dimension of L96 `X` variables\n",
    "    J = 10                              # Dimension of L96 `Y` variables\n",
    "    obs_freq = 10                       # Observation frequency (number of sampling intervals (si) per observation)\n",
    "    F_truth = 10                        # F for truth signal\n",
    "    F_fcst = 10                         # F for forecast (DA) model\n",
    "    GCM_param = np.array([0, 0, 0, 0])  # Polynomial coefficicents for GCM parameterization\n",
    "    ns_da = 2000                        # Number of time samples for DA\n",
    "    ns = 2000                           # Number of time samples for truth signal\n",
    "    ns_spinup = 200                     # Number of time samples for spin up\n",
    "    dt = 0.005                          # Model timestep\n",
    "    si = 0.005                          # Truth sampling interval\n",
    "    seasonal = False                    # Option for adding a seasonal cycle to the forcing in the L96 truth model\n",
    "    B_loc = 5                           # Spatial localization radius for DA\n",
    "    DA = \"EnKF\"                         # DA method\n",
    "    nens = 100                          # Number of ensemble members for DA\n",
    "    inflate_opt = \"relaxation\"          # Method for DA model covariance inflation\n",
    "    inflate_factor = 0.2                # Inflation factor\n",
    "    hybrid_factor = 0.1                 # Inflation factor for hybrid EnKF method\n",
    "    param_DA = False                    # Switch to parameter estimation with DA\n",
    "    param_sd = [0.01, 0.02, 0.1, 0.5]   # Polynomal parameter standard deviation\n",
    "    param_inflate = \"multiplicative\"    # Method for parameter variance inflation\n",
    "    param_inf_factor = 0.02             # Parameter inflation factor\n",
    "    obs_density = 0.2                   # Fraction of spatial gridpoints where observations are collected\n",
    "    DA_freq = 10                        # Assimilation frequency (number of sampling intervals (si) per assimilation step)\n",
    "    obs_sigma = 0.5                     # Observational error standard deviation\n",
    "    save_fig = False                    # Switch to save figure file\n",
    "    save_data = False                   # Switch to save\n",
    "    # fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824759d-3678-4915-9793-55595d0989e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def observation_operator(K, l_obs, t_obs, i_t):\n",
    "    \"\"\"Observation operator to map between model and observation space,\n",
    "    assuming linearity and model space observations.\n",
    "\n",
    "    Args:\n",
    "        K: spatial dimension of the model\n",
    "        l_obs: spatial positions of observations on model grid\n",
    "        t_obs: time positions of observations\n",
    "        i_t: the timestep of the current DA cycle\n",
    "\n",
    "    Returns:\n",
    "        Operator matrix (K * observation_density, K)\n",
    "    \"\"\"\n",
    "    n = l_obs.shape[-1]\n",
    "    H = np.zeros((n, K))\n",
    "    H[range(n), l_obs[t_obs == i_t]] = 1\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf223e6-ed8a-425a-b808-55b0cc59c69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GCM(X_init, F, dt, nt, param=[0]):\n",
    "    \"\"\"A toy `General Circulation Model` (GCM) that uses the single time-scale Lorenz 1996 model\n",
    "    with a parameterised coupling term to represent the interaction between the observed coarse\n",
    "    scale processes `X` and unobserved fine scale processes `Y` of the two time-scale model.\n",
    "\n",
    "    Args:\n",
    "        X_init: Initial conditions of X\n",
    "        F: Forcing term\n",
    "        dt: Sampling frequency of the model\n",
    "        nt: Number of timesteps for which to run the model\n",
    "        param: Weights to give to the coupling term\n",
    "\n",
    "    Returns:\n",
    "        Model output for all variables of X at each timestep along with the corresponding time units\n",
    "    \"\"\"\n",
    "    time, hist, X = (\n",
    "        dt * np.arange(nt + 1),\n",
    "        np.zeros((nt + 1, len(X_init))) * np.nan,\n",
    "        X_init.copy(),\n",
    "    )\n",
    "    hist[0] = X\n",
    "\n",
    "    for n in range(nt):\n",
    "        X = X + dt * (L96_eq1_xdot(X, F) - np.polyval(param, X))\n",
    "        hist[n + 1], time[n + 1] = X, dt * (n + 1)\n",
    "\n",
    "    return hist, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65b0ea-ba54-406e-878c-39b46e776022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dist(i, j, K):\n",
    "    \"\"\"Compute the absolute distance between two element indices\n",
    "    within a square matrix of size (K x K)\n",
    "\n",
    "    Args:\n",
    "        i: the ith row index\n",
    "        j: the jth column index\n",
    "        K: shape of square array\n",
    "\n",
    "    Returns:\n",
    "        Distance\n",
    "    \"\"\"\n",
    "    return abs(i - j) if abs(i - j) <= K / 2 else K - abs(i - j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab2c12b-3b13-4557-9228-60222de7470c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaspari_cohn(distance, radius):\n",
    "    \"\"\"Compute the appropriate distance dependent weighting of a\n",
    "    covariance matrix, after Gaspari & Cohn, 1999 (https://doi.org/10.1002/qj.49712555417)\n",
    "\n",
    "    Args:\n",
    "        distance: the distance between array elements\n",
    "        radius: localization radius for DA\n",
    "\n",
    "    Returns:\n",
    "        distance dependent weight of the (i,j) index of a covariance matrix\n",
    "    \"\"\"\n",
    "    if distance == 0:\n",
    "        weight = 1.0\n",
    "    else:\n",
    "        if radius == 0:\n",
    "            weight = 0.0\n",
    "        else:\n",
    "            ratio = distance / radius\n",
    "            weight = 0.0\n",
    "            if ratio <= 1:\n",
    "                weight = (\n",
    "                    -(ratio**5) / 4\n",
    "                    + ratio**4 / 2\n",
    "                    + 5 * ratio**3 / 8\n",
    "                    - 5 * ratio**2 / 3\n",
    "                    + 1\n",
    "                )\n",
    "            elif ratio <= 2:\n",
    "                weight = (\n",
    "                    ratio**5 / 12\n",
    "                    - ratio**4 / 2\n",
    "                    + 5 * ratio**3 / 8\n",
    "                    + 5 * ratio**2 / 3\n",
    "                    - 5 * ratio\n",
    "                    + 4\n",
    "                    - 2 / 3 / ratio\n",
    "                )\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f93dee-eea4-44e0-9ad6-113ab0912688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def localize_covariance(B, loc=0):\n",
    "    \"\"\"Localize the model climatology covariance matrix, based on\n",
    "    the Gaspari-Cohn function.\n",
    "\n",
    "    Args:\n",
    "        B: Covariance matrix over a long model run 'M_truth' (K, K)\n",
    "        loc: spatial localization radius for DA\n",
    "\n",
    "    Returns:\n",
    "        Covariance matrix scaled to zero outside distance 'loc' from diagonal and\n",
    "        the matrix of weights which are used to scale covariance matrix\n",
    "    \"\"\"\n",
    "    M, N = B.shape\n",
    "    X, Y = np.ix_(np.arange(M), np.arange(N))\n",
    "    dist = np.vectorize(get_dist)(X, Y, M)\n",
    "    W = np.vectorize(gaspari_cohn)(dist, loc)\n",
    "    return B * W, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b629d-398b-4b96-9d63-e95eaab8f688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def running_average(X, N):\n",
    "    \"\"\"Compute running mean over a user-specified window.\n",
    "\n",
    "    Args:\n",
    "        X: Input vector of arbitrary length 'n'\n",
    "        N: Size of window over which to compute mean\n",
    "\n",
    "    Returns:\n",
    "        X averaged over window N\n",
    "    \"\"\"\n",
    "    if N % 2 == 0:\n",
    "        N1, N2 = -N / 2, N / 2\n",
    "    else:\n",
    "        N1, N2 = -(N - 1) / 2, (N + 1) / 2\n",
    "    X_sum = np.zeros(X.shape)\n",
    "    for i in np.arange(N1, N2):\n",
    "        X_sum = X_sum + np.roll(X, int(i), axis=0)\n",
    "    return X_sum / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a648d4-d5af-419c-bdaa-9dd81b14cffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_obs(loc, obs, t_obs, l_obs, period):\n",
    "    \"\"\"NOTE: This function is for plotting purposes only.\"\"\"\n",
    "    t_period = np.where((t_obs[:, 0] >= period[0]) & (t_obs[:, 0] < period[1]))\n",
    "    obs_period = np.zeros(t_period[0].shape)\n",
    "    obs_period[:] = np.nan\n",
    "    for i in np.arange(len(obs_period)):\n",
    "        if np.any(l_obs[t_period[0][i]] == loc):\n",
    "            obs_period[i] = obs[t_period[0][i]][l_obs[t_period[0][i]] == loc]\n",
    "    return obs_period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3052af",
   "metadata": {},
   "source": [
    "# 2. Generate `truth` run from two time-scale L96 model\n",
    "\n",
    "We initialise the L96 two time-scale model using a set of random normally distributed values for $X$, and zeros for $Y$, and run it forward for a period `ns_spinup` to allow the model to spinup. The $X$ and $Y$ components of the spinup are then used as initial conditions for another forward run for a time period `ns` to represent the unobserved `truth` field from which our observations will be derived.\n",
    "\n",
    "_Note that in reality we do not observe the fine scale components ($Y$s) and so this is what we aim to represent in the parameterisation in the `GCM()` function._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393d1bd-5838-402d-a381-a617c987d1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the \"truth\" 2-scale L96 model\n",
    "M_truth = L96(Config.K, Config.J, F=Config.F_truth, dt=Config.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4696c6b-cfbd-4623-9952-bcf7a3e75783",
   "metadata": {},
   "source": [
    "Generate the initial conditions of $X$ and $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8e02a-2dec-4724-9175-f5809414533e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M_truth.set_state(rng.standard_normal((Config.K)), 0 * M_truth.j)\n",
    "\n",
    "# The model runs for `ns_spinup` timesteps to spin-up\n",
    "X_spinup, Y_spinup, t_spinup = M_truth.run(Config.si, Config.si * Config.ns_spinup)\n",
    "\n",
    "# The initial conditions for the first forecast (prior to DA)\n",
    "# are the last time sample after spinup\n",
    "X_init = X_spinup[-1, :]\n",
    "Y_init = Y_spinup[-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c402e-e083-4cfe-b678-d4d8cd5e098f",
   "metadata": {},
   "source": [
    "Using the generated initial conditions above, run **L96** to generate the `truth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f3b33-7cf7-47ae-9460-f735f8d46627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M_truth.set_state(X_init, Y_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916b273-2823-4c6c-b3e4-fd1f3b5ce805",
   "metadata": {},
   "source": [
    "If given in `Config`, give `F` a **seasonal cycle** in the truth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceac2dd-543e-4688-99ce-a7eb2bcc4e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.seasonal:\n",
    "    ann_period = 2000\n",
    "    mon_period = 100\n",
    "    mon_per_ann = ann_period / mon_period\n",
    "    X_truth, Y_truth, t_truth = M_truth.run(Config.si, Config.si * mon_period)\n",
    "    for i in range(1, int(Config.ns / mon_period)):\n",
    "        M_truth.set_state(X_truth[-1, ...], Y_truth[-1, ...])\n",
    "        M_truth.set_param(F=Config.F_truth + 2 * np.sin(2 * np.pi * i / mon_per_ann))\n",
    "        X_step, Y_step, t_step = M_truth.run(Config.si, Config.si * mon_period)\n",
    "        X_truth = np.concatenate((X_truth, X_step[1:None, ...]))\n",
    "        Y_truth = np.concatenate((Y_truth, Y_step[1:None, ...]))\n",
    "        t_truth = np.concatenate((t_truth, t_truth[-1] + t_step[1:None]))\n",
    "else:\n",
    "    X_truth, Y_truth, t_truth = M_truth.run(Config.si, Config.si * Config.ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c0fef-53be-4d0b-9105-9601862f6690",
   "metadata": {},
   "source": [
    "Now, we generate climatological background (temporal) covariance for the 2-scale L96 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac4faf-ff3f-4152-bfb9-fcdb1f2c2234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_clim2 = np.cov(X_truth.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df79fe-b945-43be-b08a-b63b93bca400",
   "metadata": {},
   "source": [
    "Plotting values of $X$ and $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66be99-a6d1-4134-92a4-e1a2ab8a6916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10), dpi=150)\n",
    "plt.subplot(221)\n",
    "\n",
    "# Snapshot of X[k]\n",
    "plt.plot(M_truth.k, X_truth[-1, :], label=\"X\")\n",
    "plt.plot(M_truth.j / M_truth.J, Y_truth[-1, :], label=\"Y\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"k\")\n",
    "plt.title(\"$X,Y$ @ $t=N\\Delta t$\")\n",
    "plt.plot(M_truth.k, X_truth[0, :], \"k:\")\n",
    "plt.plot(M_truth.j / M_truth.J, Y_truth[0, :], \"k:\")\n",
    "plt.subplot(222)\n",
    "\n",
    "# Sample time-series X[0](t), Y[0](t)\n",
    "plt.plot(t_truth, X_truth[:, 0], label=\"X\")\n",
    "plt.plot(t_truth, Y_truth[:, 0], label=\"Y\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.title(\"$X[0,t]$, $Y[0,t]$\")\n",
    "plt.subplot(223)\n",
    "\n",
    "# Full model history of X\n",
    "plt.contourf(M_truth.k, t_truth, X_truth)\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.title(\"$X(k,t)$\")\n",
    "plt.subplot(224)\n",
    "\n",
    "# Full model history of Y\n",
    "plt.contourf(M_truth.j / M_truth.J, t_truth, Y_truth)\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.title(\"$Y(k,t)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17c582-090e-48bf-b26a-adbd66fdbefb",
   "metadata": {},
   "source": [
    "Generating climatological background covariance for 1-scale L96 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b5cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M_1s = L96s(Config.K, F=Config.F_truth, dt=Config.dt, method=RK4)\n",
    "M_1s.set_state(X_init)\n",
    "X1_truth, t1_truth = M_1s.run(Config.si * Config.ns)\n",
    "B_clim1 = np.cov(X1_truth.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f14f72",
   "metadata": {},
   "source": [
    "# 3. Generate synthetic observations\n",
    "\n",
    "Here we generate a set of sparse observations by sampling from the `X_truth` run and adding some random Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dbe50-741b-4ce5-88ac-4f583e19d11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample the \"truth\" to generate observations at certain times (t_obs) and locations (l_obs)\n",
    "t_obs = np.tile(\n",
    "    np.arange(Config.obs_freq, Config.ns_da + Config.obs_freq, Config.obs_freq),\n",
    "    [int(Config.K * Config.obs_density), 1],\n",
    ").T\n",
    "\n",
    "l_obs = np.zeros(t_obs.shape, dtype=\"int\")\n",
    "for i in range(l_obs.shape[0]):\n",
    "    l_obs[i, :] = rng.choice(\n",
    "        Config.K, int(Config.K * Config.obs_density), replace=False\n",
    "    )\n",
    "\n",
    "X_obs = X_truth[t_obs, l_obs] + Config.obs_sigma * rng.standard_normal(l_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee8b4d-0539-4621-8d45-30769452a155",
   "metadata": {},
   "source": [
    "The covariance matrix over the observations `R` (used to express the uncertainty in the observations during DA) is given as a diagonal matrix with entries defined by the square of the \"observational error standard deviation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculated observation covariance matrix, assuming independent observations\n",
    "R = Config.obs_sigma**2 * np.eye(int(Config.K * Config.obs_density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34000d8e-bb3c-4ca7-b760-e186ec7c2f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 6], dpi=150)\n",
    "plt.plot(range(1000, 1500), X_truth[1000:1500, 0], label=\"truth\")\n",
    "plt.scatter(\n",
    "    t_obs[100:150, 0],\n",
    "    find_obs(0, X_obs, t_obs, l_obs, [t_obs[100, 0], t_obs[150, 0]]),\n",
    "    color=\"k\",\n",
    "    label=\"obs\",\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bc6d5",
   "metadata": {},
   "source": [
    "# 4. Apply Localization to the Background Model Covariance\n",
    "\n",
    "The covariance of the model climatology was computed a-priori from a long run. In this step we apply the localized weighting to the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5501b8-82d7-428a-a030-47d8c50fc4bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import DA_methods\n",
    "\n",
    "importlib.reload(DA_methods);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb095211-2a3f-47c1-899c-ecd4bc4a802d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Load pre-calculated climatological background covariance matrix from a long simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053ebb0-0e36-41cc-bca5-141ddd15a165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_loc, W_clim = localize_covariance(B_clim1, loc=Config.B_loc)\n",
    "\n",
    "B_corr1 = np.zeros(B_clim1.shape)\n",
    "B_corr2 = np.zeros(B_clim2.shape)\n",
    "for i in range(B_clim1.shape[0]):\n",
    "    for j in range(B_clim1.shape[1]):\n",
    "        B_corr1[i, j] = B_clim1[i, j] / np.sqrt(B_clim1[i, i] * B_clim1[j, j])\n",
    "        B_corr2[i, j] = B_clim2[i, j] / np.sqrt(B_clim2[i, i] * B_clim2[j, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e9b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6), dpi=150)\n",
    "plt.subplot(121)\n",
    "plt.contourf(B_corr1, cmap=\"bwr\", extend=\"both\", levels=np.linspace(-0.95, 0.95, 20))\n",
    "plt.colorbar()\n",
    "plt.title(\"Background correlation matrix: 1-scale L96\")\n",
    "plt.subplot(122)\n",
    "plt.contourf(B_corr2, cmap=\"bwr\", extend=\"both\", levels=np.linspace(-0.95, 0.95, 20))\n",
    "plt.colorbar()\n",
    "plt.title(\"Background correlation matrix: 2-scale L96\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a249a",
   "metadata": {},
   "source": [
    "# 4. Run Data Assimilation\n",
    "\n",
    "During each DA cycle, we produce an updated state estimate for all $K$ grid points, and all `n` number of ensemble members.\n",
    "\n",
    "The inputs are:\n",
    "\n",
    "- prior estimate (the forecast at time t for all K grid points, and all n number of ensemble members)\n",
    "- observations (N observations)\n",
    "- operator matrix (N x K)\n",
    "- covariance over obs (N x N)\n",
    "- covariance over model (K x K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5c9f4-0ae8-4d07-a458-6d2b1ec4af33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Set up array to store DA increments\n",
    "X_inc = np.zeros((int(Config.ns_da / Config.DA_freq), Config.K, Config.nens))\n",
    "if Config.DA == \"3DVar\":\n",
    "    X_inc = np.squeeze(X_inc)\n",
    "\n",
    "t_DA = np.zeros(int(Config.ns_da / Config.DA_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49ce4c-2a11-4207-9bd1-05b16607b2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize ensemble with perturbations\n",
    "i_t = 0\n",
    "ensX = X_init[None, :, None] + rng.standard_normal((1, Config.K, Config.nens))\n",
    "X_post = ensX[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c576b-be9f-4353-9172-455853f08d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Config.param_DA:\n",
    "    mean_param = np.zeros((int(Config.ns_da / Config.DA_freq), len(Config.GCM_param)))\n",
    "    spread_param = np.zeros((int(Config.ns_da / Config.DA_freq), len(Config.GCM_param)))\n",
    "    param_scale = Config.param_sd\n",
    "    W = np.ones((Config.K + len(Config.GCM_param), Config.K + len(Config.GCM_param)))\n",
    "    W[0 : Config.K, 0 : Config.K] = W_clim\n",
    "else:\n",
    "    W = W_clim\n",
    "    param_scale = np.zeros(Config.GCM_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e95487-435f-4bd4-bfab-6e0cb6893b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ens_param = np.zeros((len(Config.GCM_param), Config.nens))\n",
    "for i in range(len(Config.GCM_param)):\n",
    "    ens_param[i, :] = Config.GCM_param[i] + rng.normal(\n",
    "        scale=param_scale[i], size=Config.nens\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef8b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cycle in np.arange(0, Config.ns_da / Config.DA_freq, dtype=int):\n",
    "    # Set up array to store model forecast for each DA cycle\n",
    "    ensX_fcst = np.zeros((Config.DA_freq + 1, Config.K, Config.nens))\n",
    "\n",
    "    # Model forecast for next DA cycle\n",
    "    for n in range(Config.nens):\n",
    "        ensX_fcst[..., n] = GCM(\n",
    "            X_post[0 : Config.K, n],\n",
    "            Config.F_fcst,\n",
    "            Config.dt,\n",
    "            Config.DA_freq,\n",
    "            ens_param[:, n],\n",
    "        )[0]\n",
    "\n",
    "    i_t = i_t + Config.DA_freq\n",
    "\n",
    "    # Get prior/background from the forecast\n",
    "    X_prior = ensX_fcst[-1, ...]\n",
    "\n",
    "    # Call DA\n",
    "    t_DA[cycle] = t_truth[i_t]\n",
    "    if Config.DA == \"EnKF\":\n",
    "        H = observation_operator(Config.K, l_obs, t_obs, i_t)\n",
    "\n",
    "        # Augment state vector with parameters when doing parameter estimation\n",
    "        if Config.param_DA:\n",
    "            H = np.concatenate(\n",
    "                (H, np.zeros((H.shape[0], len(Config.GCM_param)))), axis=-1\n",
    "            )\n",
    "            X_prior = np.concatenate((X_prior, ens_param))\n",
    "        B_ens = np.cov(X_prior)\n",
    "        B_ens_loc = B_ens * W\n",
    "        X_post = DA_methods.EnKF(X_prior, X_obs[t_obs == i_t], H, R, B_ens_loc)\n",
    "\n",
    "        X_post[0 : Config.K, :] = DA_methods.ens_inflate(\n",
    "            X_post[0 : Config.K, :],\n",
    "            X_prior[0 : Config.K, :],\n",
    "            Config.inflate_opt,\n",
    "            Config.inflate_factor,\n",
    "        )\n",
    "\n",
    "        if Config.param_DA:\n",
    "            X_post[-len(Config.GCM_param) :, :] = DA_methods.ens_inflate(\n",
    "                X_post[-len(Config.GCM_param) :, :],\n",
    "                X_prior[-len(Config.GCM_param) :, :],\n",
    "                Config.param_inflate,\n",
    "                Config.param_inf_factor,\n",
    "            )\n",
    "            ens_param = X_post[-len(Config.GCM_param) :, :]\n",
    "\n",
    "    elif Config.DA == \"HyEnKF\":\n",
    "        H = observation_operator(Config.K, l_obs, t_obs, i_t)\n",
    "        B_ens = (\n",
    "            np.cov(X_prior) * (1 - Config.hybrid_factor)\n",
    "            + B_clim1 * Config.hybrid_factor\n",
    "        )\n",
    "        B_ens_loc = B_ens * W\n",
    "        X_post = DA_methods.EnKF(X_prior, X_obs[t_obs == i_t], H, R, B_ens_loc)\n",
    "        X_post = DA_methods.ens_inflate(\n",
    "            X_post, X_prior, Config.inflate_opt, Config.inflate_factor\n",
    "        )\n",
    "\n",
    "    elif Config.DA == \"3DVar\":\n",
    "        X_prior = np.squeeze(X_prior)\n",
    "        H = observation_operator(Config.K, l_obs, t_obs, i_t)\n",
    "        X_post = DA_methods.Lin3dvar(X_prior, X_obs[t_obs == i_t], H, R, B_loc, 3)\n",
    "\n",
    "    elif Config.DA == \"Replace\":\n",
    "        X_post = X_prior\n",
    "        X_post[l_obs[t_obs == i_t]] = X_obs[t_obs == i_t]\n",
    "\n",
    "    elif Config.DA == \"None\":\n",
    "        X_post = X_prior\n",
    "\n",
    "    if not Config.DA == \"None\":\n",
    "        # Get current increments\n",
    "        X_inc[cycle, ...] = (\n",
    "            np.squeeze(X_post[0 : Config.K, ...]) - X_prior[0 : Config.K, ...]\n",
    "        )\n",
    "\n",
    "        # Get posterior info about the estimated parameters\n",
    "        if Config.param_DA:\n",
    "            mean_param[cycle, :] = ens_param.mean(axis=-1)\n",
    "            spread_param[cycle, :] = ens_param.std(axis=-1)\n",
    "\n",
    "    # Reset initial conditions for next DA cycle\n",
    "    ensX_fcst[-1, :, :] = X_post[0 : Config.K, :]\n",
    "    ensX = np.concatenate((ensX, ensX_fcst[1:None, ...]))\n",
    "\n",
    "print(f\"Time to complete DA: {round(time.time() - start_time, 2)} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d243a69",
   "metadata": {},
   "source": [
    "# 5. Post Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c37a85-433c-4d2e-a49c-1daf4f6a9ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_X = np.mean(ensX, axis=-1)\n",
    "clim = np.max(np.abs(mean_X - X_truth[0 : (Config.ns_da + 1), :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f05d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "ch = axes[0, 0].contourf(\n",
    "    M_truth.k,\n",
    "    t_truth[0 : (Config.ns_da + 1)],\n",
    "    mean_X - X_truth[0 : (Config.ns_da + 1), :],\n",
    "    cmap=\"bwr\",\n",
    "    vmin=-clim,\n",
    "    vmax=clim,\n",
    "    extend=\"neither\",\n",
    ")\n",
    "\n",
    "plt.colorbar(ch, ax=axes[0, 0], orientation=\"horizontal\")\n",
    "axes[0, 0].set_xlabel(\"s\")\n",
    "axes[0, 0].set_ylabel(\"t\", rotation=0)\n",
    "axes[0, 0].set_title(\"X - X_truth\")\n",
    "\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (Config.ns_da + 1)],\n",
    "    np.sqrt(((mean_X - X_truth[0 : (Config.ns_da + 1), :]) ** 2).mean(axis=-1)),\n",
    "    label=\"RMSE\",\n",
    ")\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (Config.ns_da + 1)],\n",
    "    np.mean(np.std(ensX, axis=-1), axis=-1),\n",
    "    label=\"Spread\",\n",
    ")\n",
    "axes[0, 1].plot(\n",
    "    t_truth[0 : (Config.ns_da + 1)],\n",
    "    Config.obs_sigma * np.ones((Config.ns_da + 1)),\n",
    "    label=\"Obs error\",\n",
    ")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xlabel(\"time\")\n",
    "axes[0, 1].set_title(\"RMSE (X - X_truth)\")\n",
    "axes[0, 1].grid(which=\"both\", linestyle=\"--\")\n",
    "\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.sqrt(((mean_X - X_truth[0 : (Config.ns_da + 1), :]) ** 2).mean(axis=0)),\n",
    "    label=\"RMSE\",\n",
    ")\n",
    "X_inc_ave = X_inc / Config.DA_freq / Config.si\n",
    "axes[0, 2].plot(M_truth.k, X_inc_ave.mean(axis=(0, -1)), label=\"Inc\")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k, running_average(X_inc_ave.mean(axis=(0, -1)), 7), label=\"Inc Ave\"\n",
    ")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.ones(M_truth.k.shape) * (Config.F_fcst - Config.F_truth),\n",
    "    label=\"F_bias\",\n",
    ")\n",
    "axes[0, 2].plot(\n",
    "    M_truth.k,\n",
    "    np.ones(M_truth.k.shape) * (X_inc / Config.DA_freq / Config.si).mean(),\n",
    "    \"k:\",\n",
    "    label=\"Ave Inc\",\n",
    ")\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].set_xlabel(\"s\")\n",
    "axes[0, 2].set_title(\"Increments\")\n",
    "axes[0, 2].grid(which=\"both\", linestyle=\"--\")\n",
    "\n",
    "plot_start, plot_end = 1000, 1500\n",
    "plot_start_DA, plot_end_DA = int(plot_start / Config.DA_freq), int(\n",
    "    plot_end / Config.DA_freq\n",
    ")\n",
    "plot_x = 0\n",
    "\n",
    "axes[1, 0].plot(\n",
    "    t_truth[plot_start:plot_end], X_truth[plot_start:plot_end, plot_x], label=\"truth\"\n",
    ")\n",
    "axes[1, 0].plot(\n",
    "    t_truth[plot_start:plot_end], mean_X[plot_start:plot_end, plot_x], label=\"forecast\"\n",
    ")\n",
    "axes[1, 0].scatter(\n",
    "    t_DA[plot_start_DA - 1 : plot_end_DA - 1],\n",
    "    find_obs(plot_x, X_obs, t_obs, l_obs, [plot_start, plot_end]),\n",
    "    label=\"obs\",\n",
    ")\n",
    "axes[1, 0].grid(which=\"both\", linestyle=\"--\")\n",
    "axes[1, 0].set_xlabel(\"time\")\n",
    "axes[1, 0].set_title(\"k=\" + str(plot_x + 1) + \" truth and forecast\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "if Config.param_DA:\n",
    "    for i, c in zip(np.arange(len(Config.GCM_param), 0, -1), [\"r\", \"b\", \"g\", \"k\"]):\n",
    "        axes[1, 1].plot(\n",
    "            t_DA,\n",
    "            running_average(mean_param[:, i - 1], 100),\n",
    "            c + \"-\",\n",
    "            label=\"C{} {:3f}\".format(\n",
    "                i - 1, mean_param[int(len(t_DA) / 2) :, i - 1].mean()\n",
    "            ),\n",
    "        )\n",
    "        axes[1, 1].plot(\n",
    "            t_DA,\n",
    "            running_average(mean_param[:, i - 1] + spread_param[:, i - 1], 100),\n",
    "            c + \":\",\n",
    "            label=f\"SD {spread_param[int(len(t_DA) / 2):, i - 1].mean():3f}\",\n",
    "        )\n",
    "        axes[1, 1].plot(\n",
    "            t_DA,\n",
    "            running_average(mean_param[:, i - 1] - spread_param[:, i - 1], 100),\n",
    "            c + \":\",\n",
    "        )\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(which=\"both\", linestyle=\"--\")\n",
    "\n",
    "else:\n",
    "    axes[1, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 2].text(\n",
    "    0.1,\n",
    "    0.2,\n",
    "    (\n",
    "        f\"RMSE={np.sqrt(((mean_X - X_truth[0 : (Config.ns_da + 1), :]) ** 2).mean()):3f}\\n\"\n",
    "        f\"Spread={np.mean(np.std(ensX, axis=-1)):3f}\\n\"\n",
    "        f\"GCM param={Config.GCM_param}\\n\"\n",
    "        f\"DA={Config.DA}, {Config.nens}\\n\"\n",
    "        f\"DA_freq={Config.DA_freq}\\n\"\n",
    "        f\"B_loc={Config.B_loc}\\n\"\n",
    "        f\"inflation={Config.inflate_opt}, {Config.inflate_factor}\\n\"\n",
    "        f\"obs_density={Config.obs_density}\\n\"\n",
    "        f\"obs_sigma={Config.obs_sigma}\\n\"\n",
    "        f\"obs_freq={Config.obs_freq}\\n\"\n",
    "    ),\n",
    "    fontsize=15,\n",
    ")\n",
    "axes[1, 2].axis(\"off\")\n",
    "\n",
    "if Config.save_fig:\n",
    "    output_dir = os.path.join(\".\", \"DA_data\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    exp_number = np.random.randint(1, 10000)\n",
    "    with open(os.path.join(output_dir, f\"config_{exp_number}.txt\"), \"w\") as f:\n",
    "        f.write(\n",
    "            output_dir\n",
    "            + str({k: v for k, v in Config.__dict__.items() if not k.startswith(\"_\")})\n",
    "        )\n",
    "    plt.savefig(os.path.join(output_dir, f\"fig_{exp_number}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63475b82-5e45-4a2c-93f5-f0e089320c7b",
   "metadata": {},
   "source": [
    "Save DA output for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65993585",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.save_data:\n",
    "    output_filename = (\n",
    "        f\"K_{Config.K}_\"\n",
    "        f\"J_{Config.J}_\"\n",
    "        f\"obs_freq_{Config.obs_freq}_\"\n",
    "        f\"F_truth_{Config.F_truth}_\"\n",
    "        f\"F_fcst_{Config.F_fcst}_\"\n",
    "        f\"ns_da_{Config.ns_da}_\"\n",
    "        f\"ns_{Config.ns}_\"\n",
    "        f\"ns_spinup_{Config.ns_spinup}_\"\n",
    "        f\"dt_{Config.dt}_\"\n",
    "        f\"si_{Config.si}_\"\n",
    "        f\"B_loc_{Config.B_loc}_\"\n",
    "        f\"DA_{Config.DA}_\"\n",
    "        f\"nens_{Config.nens}_\"\n",
    "        f\"inflate_opt_{Config.inflate_opt}_\"\n",
    "        f\"inflate_factor_{Config.inflate_factor}_\"\n",
    "        f\"hybrid_factor_{Config.hybrid_factor}_\"\n",
    "        f\"obs_density_{Config.obs_density}_\"\n",
    "        f\"DA_freq_{Config.DA_freq}_\"\n",
    "        f\"obs_sigma_{Config.obs_sigma}.npz\"\n",
    "    )\n",
    "    output_dir = os.path.join(\".\", \"DA_data\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    np.savez(\n",
    "        os.path.join(output_dir, output_filename),\n",
    "        mean_X=mean_X,\n",
    "        X_truth=X_truth,\n",
    "        X_inc_ave=X_inc_ave,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
