

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Using Neural Networks for L96 Parameterization: Online Training &#8212; Learning Machine Learning with Lorenz-96</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/L96_online_training_NN';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Improving Performance of Neural Networks" href="Improving_Neural_networks.html" />
    <link rel="prev" title="Using Neural Networks for L96 Parameterization: Online Testing" href="L96_online_implement_NN.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/newlogo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/newlogo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
    <p class="title logo__title">Learning Machine Learning with Lorenz-96</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lorenz-96 and General Circulation Models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="L96-two-scale-description.html">The Lorenz-96 Two-Timescale System</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm-analogue.html">The Lorenz-96 and its GCM Analog</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm-parameterization-problem.html">GCM parameterizations, skill metrics, and other sources of uncertainity</a></li>
<li class="toctree-l1"><a class="reference internal" href="estimating-gcm-parameters.html">Tuning GCM Parameterizations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Networks with Lorenz-96</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro_ML_and_NNs.html">Introduction to Machine Learning and Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="L96_offline_training_NN.html">Using Neural Networks for L96 Parameterization: Offline Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="L96_online_implement_NN.html">Using Neural Networks for L96 Parameterization: Online Testing</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Using Neural Networks for L96 Parameterization: Online Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="Improving_Neural_networks.html">Improving Performance of Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Neural-Network-Interpretation.html">Interpreting Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="constraints.html">Adding constraints to Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Assimilation with Lorenz-96</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DA_demo_L96.html">Data Assimilation demo in the Lorenz 96 (L96) two time-scale model</a></li>
<li class="toctree-l1"><a class="reference internal" href="Learning-DA-increments.html">Learning Data Assimilation Increments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Equation Discovery with Lorenz-96</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="symbolic_methods_comparison.html">Introduction to Equation Discovery - Comparing Symbolic Regression Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="sindy_L96_2scale.html">Applying SINDy equation identification to L96</a></li>

<li class="toctree-l1"><a class="reference internal" href="symbolic_vs_nn_multiscale_L96.html">Symbolic Regression vs. Neural Networks on Multiscale L96</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other ML approaches for Lorenz-96</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="random_forest_parameterization.html">Random Forest</a></li>
<li class="toctree-l1"><a class="reference internal" href="GP_lorenz96.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="local_map_L96_and_Burgers.html">CNNs and Polynomial Maps</a></li>




<li class="toctree-l1"><a class="reference internal" href="L96_ResNet_RNN.html">ResNet and Recurrent Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">End Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="closing_remarks.html">Outlook</a></li>
<li class="toctree-l1"><a class="reference internal" href="citing.html">Citing this book</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/L96_online_training_NN.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Using Neural Networks for L96 Parameterization: Online Training</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-vs-offline-training">Online vs offline training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-ground-truth-dataset-from-the-real-world">Generate the Ground Truth Dataset from the <em>Real World</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-differentiable-1-time-scale-l96-model">Create a differentiable 1 time-scale L96 model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-neural-network-for-the-parameterization">Define a Neural Network for the parameterization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function-and-optimizer-for-online-training">Loss function and optimizer for online training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-in-a-simulation-online-testing">Test in a simulation: Online testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="using-neural-networks-for-l96-parameterization-online-training">
<h1>Using Neural Networks for L96 Parameterization: Online Training<a class="headerlink" href="#using-neural-networks-for-l96-parameterization-online-training" title="Permalink to this headline">#</a></h1>
<div class="section" id="outline">
<h2>Outline:<a class="headerlink" href="#outline" title="Permalink to this headline">#</a></h2>
<p>In the previous two notebooks we showed how a parameterization can be developed for the L96 setup using neural networks using a methodology known as offline training. In this notebook we dive into an alternative training philosophy known as online training.</p>
</div>
<div class="section" id="online-vs-offline-training">
<h2>Online vs offline training<a class="headerlink" href="#online-vs-offline-training" title="Permalink to this headline">#</a></h2>
<p>The type of ML training done in the previous couple of notebooks, where we estimate the sub-grid terms explicitly as the terms corresponding to the missing scales from a full simulations, is known as offline training. In this training procedure it is assumed that know exactly how to estimate the effect of the missing scales. However, this might not be true in general. For the L96 case there can be differences in the numerics of the one time scale and two time scale models, which will not be accounted for in the sub-grid terms we estimate from the two time-scale more. In more general simulations, e.g. turbulent flows, a clear scale separation into scales is not available, and it is not obvious what the right way to filter the high resolution simulation might be. Additionally, the parameterization learnt using the offline procedure may turn out to be unstable because numerical stability of the parameterized model was never imposed as a constraint during the traing procedure.</p>
<p>An alternate way to train machine learning models is called online training. In this procedure, rather than training a model that best fits a pre-defined sub-grid tendency, a model is trained which tries to produce a solution of the parameterized low resolution model (<span class="math notranslate nohighlight">\(X^{param-LR}\)</span>) that is closest to the high resolution model (<span class="math notranslate nohighlight">\(X^{HR}\)</span>, where this <span class="math notranslate nohighlight">\(X\)</span> has been appropriately downscaled to match the resolution of the low resolution model). For the L96 simulation, this would imply that the parameterized one time-scale model match the evolution of the slow variables in the two-time scale model.</p>
<p>A corresponding loss function may be defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a8b7dc0d-b18f-4690-944e-354a4d625121">
<span class="eqno">(11)<a class="headerlink" href="#equation-a8b7dc0d-b18f-4690-944e-354a4d625121" title="Permalink to this equation">#</a></span>\[\begin{equation}
L^{Online} = \frac{1}{T}\int_0^T |X^{param-LR} - X^{HR}|^2 dt
\end{equation}\]</div>
<p>Contrast this to the loss function offline training:</p>
<div class="amsmath math notranslate nohighlight" id="equation-2f210e4e-421d-4a3b-bf26-98b5e31daa04">
<span class="eqno">(12)<a class="headerlink" href="#equation-2f210e4e-421d-4a3b-bf26-98b5e31daa04" title="Permalink to this equation">#</a></span>\[\begin{equation}
L^{Offline} = |P(X_k^{LR}) - U_k|^2,
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(P(X)\)</span> is the parameterization of the sub-grid terms (coupling terms) <span class="math notranslate nohighlight">\(U\)</span>. <em>Note that in both of the loss functions above appropriate averages over available samples are taken.</em></p>
<p>So, let’s see how this can be done in practice, and what technical changes we need to make.</p>
<p>Note: Much of this notebook has been inspired by Pavel Perezhogin’s <a class="reference external" href="https://github.com/Pperezhogin/L96-predictability">repo</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">Data</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>

<span class="kn">from</span> <span class="nn">L96_model</span> <span class="kn">import</span> <span class="n">L96</span><span class="p">,</span> <span class="n">RK2</span><span class="p">,</span> <span class="n">RK4</span><span class="p">,</span> <span class="n">EulerFwd</span><span class="p">,</span> <span class="n">L96_eq1_xdot</span><span class="p">,</span> <span class="n">integrate_L96_2t</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensuring reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">14</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">14</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) # You can try this if you have a GPU. However, speed up on GPU is only guaranteed after overhead cost of moving data between CPU and GPU is accounted for.</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="generate-the-ground-truth-dataset-from-the-real-world">
<h2>Generate the Ground Truth Dataset from the <em>Real World</em><a class="headerlink" href="#generate-the-ground-truth-dataset-from-the-real-world" title="Permalink to this headline">#</a></h2>
<p>Same as the past notebooks, we first generate some instance from the two-time scale (also called our “real world”) simulation.</p>
<p>We initialise the L96 two time-scale model using <span class="math notranslate nohighlight">\(K\)</span> (set to 8) values of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(J\)</span> (set to 32) values of <span class="math notranslate nohighlight">\(Y\)</span> for each <span class="math notranslate nohighlight">\(X\)</span>. The model is run for many timesteps to generate the dataset for training later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup the two time-scale model</span>
<span class="n">time_steps</span> <span class="o">=</span> <span class="mi">32000</span>
<span class="n">forcing</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">18</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">time_steps</span>

<span class="c1"># Create a &quot;real world&quot; with K=8 and J=32</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">L96</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="n">forcing</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the two time-scale model</span>

<span class="c1"># The effect of Y on X is `xy_true`</span>
<span class="n">X_true</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">store</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_coupling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Change the data type to `float32` in order to avoid doing type conversions later on</span>
<span class="n">X_true</span> <span class="o">=</span> <span class="n">X_true</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Notice that we only output the model trajectory here, as we don&#39;t need the coupling terms for training here.</span>
</pre></div>
</div>
</div>
</div>
<p>We now need to set the number of time steps that the training process will use for every sample (how long of a trajectory are we trying to match).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Tstep_train</span> <span class="o">=</span> <span class="mi">128</span>

<span class="c1"># We split the simulation into ensembles members without any overlap,</span>
<span class="c1"># and each of these will be used as a separate sample.</span>
<span class="n">N_ens</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time_steps</span> <span class="o">/</span> <span class="n">Tstep_train</span><span class="p">)</span>
<span class="n">X_true_ens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_true</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="n">N_ens</span> <span class="o">*</span> <span class="n">Tstep_train</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="n">N_ens</span><span class="p">,</span> <span class="n">Tstep_train</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the data into training and test</span>

<span class="c1"># Set the number of time series that will be part of test ensemble.</span>
<span class="n">test_ens</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Training Data</span>
<span class="n">X_true_train</span> <span class="o">=</span> <span class="n">X_true_ens</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">test_ens</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

<span class="c1"># Test Data</span>
<span class="n">X_true_test</span> <span class="o">=</span> <span class="n">X_true_ens</span><span class="p">[</span><span class="o">-</span><span class="n">test_ens</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_true_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_true_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((218, 128, 8), (32, 128, 8))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of sample in each batch</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that in the training and testing datasets defined below the input to the model is the initial condition, and the output that the model will be evaluated against is a time series from the simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training Dataset</span>
<span class="c1"># ----------------</span>
<span class="n">nlocal_data_train</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_true_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]),</span>  <span class="c1"># expected input is an initial condition</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_true_train</span><span class="p">),</span>  <span class="c1"># expected output as a time series</span>
<span class="p">)</span>

<span class="n">nlocal_loader_train</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">nlocal_data_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># Test Dataset</span>
<span class="c1"># ------------</span>
<span class="n">nlocal_data_test</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_true_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_true_test</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">nlocal_loader_test</span> <span class="o">=</span> <span class="n">Data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">nlocal_data_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-a-differentiable-1-time-scale-l96-model">
<h2>Create a differentiable 1 time-scale L96 model<a class="headerlink" href="#create-a-differentiable-1-time-scale-l96-model" title="Permalink to this headline">#</a></h2>
<p>One of the key components needed for online training is a differentiable solver. This can be seen by the presence of <span class="math notranslate nohighlight">\(X^{param-LR}\)</span> in the loss function, which indicates that derivatives should be able to pass through a function that not only corresponds to the extra terms that are added, but also produces the full solution.</p>
<p>This relatively to easy to do with modern machine learning frameworks like PyTorch or JAX, as long as the model is simple enough to be rewritten using these frameworks.</p>
<p>Here we will write a differentiable solver for :</p>
<div class="amsmath math notranslate nohighlight" id="equation-676321c2-a8fa-478c-b242-2031eb7b94a4">
<span class="eqno">(13)<a class="headerlink" href="#equation-676321c2-a8fa-478c-b242-2031eb7b94a4" title="Permalink to this equation">#</a></span>\[\begin{align}
\frac{d}{dt} X_k
&amp;= - X_{k-1} \left( X_{k-2} - X_{k+1} \right) - X_k + F.
\end{align}\]</div>
<p>Notice below that in this case this task was as simple as using the word <code class="docutils literal notranslate"><span class="pre">torch</span></code> instead of <code class="docutils literal notranslate"><span class="pre">np</span></code>, basically swapping out numpy calls with PyTorch calls.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">L96_eq1_xdot_torch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compared to older function works on batches,</span>
<span class="sd">    i.e. dimension is Nbatch x K (single time step for many batches is input)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dims</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
        <span class="o">-</span> <span class="n">X</span>
        <span class="o">+</span> <span class="n">F</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">RK4</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">kw</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the new state X(n+1) for d/dt X = fn(X,t,...) using the fourth order Runge-Kutta method.</span>
<span class="sd">    Args:</span>
<span class="sd">        fn     : The function returning the time rate of change of model variables X</span>
<span class="sd">        dt     : The time step</span>
<span class="sd">        X      : Values of X variables at the current time, t</span>
<span class="sd">        kw     : All other arguments that should be passed to fn, i.e. fn(X, t, *kw)</span>
<span class="sd">    Returns:</span>
<span class="sd">        X at t+dt</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">Xdot1</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">kw</span><span class="p">)</span>
    <span class="n">Xdot2</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">Xdot1</span><span class="p">,</span> <span class="o">*</span><span class="n">kw</span><span class="p">)</span>
    <span class="n">Xdot3</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">Xdot2</span><span class="p">,</span> <span class="o">*</span><span class="n">kw</span><span class="p">)</span>
    <span class="n">Xdot4</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">Xdot3</span><span class="p">,</span> <span class="o">*</span><span class="n">kw</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span> <span class="o">+</span> <span class="p">(</span><span class="n">dt</span> <span class="o">/</span> <span class="mf">6.0</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="n">Xdot1</span> <span class="o">+</span> <span class="n">Xdot4</span><span class="p">)</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">Xdot2</span> <span class="o">+</span> <span class="n">Xdot3</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="define-a-neural-network-for-the-parameterization">
<h2>Define a Neural Network for the parameterization<a class="headerlink" href="#define-a-neural-network-for-the-parameterization" title="Permalink to this headline">#</a></h2>
<p>Here we use a neural network architecture that is exactly the same as the non-local architecture that was used in the previous notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FCNN_nonlocal</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>  <span class="c1"># 8 inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>  <span class="c1"># 8 outputs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fcnn_online_network</span> <span class="o">=</span> <span class="n">FCNN_nonlocal</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="loss-function-and-optimizer-for-online-training">
<h2>Loss function and optimizer for online training<a class="headerlink" href="#loss-function-and-optimizer-for-online-training" title="Permalink to this headline">#</a></h2>
<p>The target of the loss function in online training is not simply to match the sub-grid fluxes, but instead to also track the solution of the two time-scale model using the single time-scale model.</p>
<p>The loss function below is where the magic happens. Notice two key elements: (1) the neural network is combined with the numerical solver that produces the tendency at every time step, (2) a time integration is performed over the number some number of time steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">NN</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NN: the neural network that parameterizes the missing terms</span>
<span class="sd">    x_in: initial conditions, which are the input. Shape (batch size X K)</span>
<span class="sd">    y_true: full solution from the two time scale model. Shape (batch size X Nt X K)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">full_xdot</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">NN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">L96_eq1_xdot_torch</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">F</span><span class="o">=</span><span class="n">forcing</span>
    <span class="p">)</span>  <span class="c1"># make a function that returns tendency with NN as param.</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">y_true</span>  <span class="c1"># Use this to store the model prediction we make</span>

    <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">x_in</span>  <span class="c1"># intiailize IC (which is the only input to model).</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># loop over time steps</span>
        <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">RK4</span><span class="p">(</span>
            <span class="n">full_xdot</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="p">)</span>  <span class="c1"># time step forward.</span>

    <span class="k">return</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Since the only free parameters correspond to the weights of the neural network, they are passed to the optimizer. Notice that even though the loss function is much more complex than the offline training case, the parameters that are being optimized are the same.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setup optimizer.</span>

<span class="n">optimizer_fcnn</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">fcnn_online_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">#</a></h2>
<p>First we define the helper functions for training, testing and fitting, same as we did in previous notebooks</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the network for one epoch&quot;&quot;&quot;</span>
    <span class="n">network</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="c1"># Compute the loss (now the predictions are done directly in the loss function).</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Clear the gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Backpropagation to compute the gradients and update the weights</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">loader</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test the network&quot;&quot;&quot;</span>
    <span class="n">network</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Evaluation mode (important when having dropout layers)</span>

    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="c1"># Compute the loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Get an average loss for the entire dataset</span>
        <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">test_loss</span>


<span class="k">def</span> <span class="nf">fit_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train and validate the network&quot;&quot;&quot;</span>
    <span class="n">train_losses</span><span class="p">,</span> <span class="n">test_losses</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">test_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
    <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed in </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">end_time</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time</span><span class="p">)</span><span class="si">}</span><span class="s2"> seconds.&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">test_losses</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Epochs refer to the number of times we iterate over the entire training data during training.</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model.</span>
<span class="n">train_loss_online</span><span class="p">,</span> <span class="n">test_loss_online</span> <span class="o">=</span> <span class="n">fit_model</span><span class="p">(</span>
    <span class="n">fcnn_online_network</span><span class="p">,</span>
    <span class="n">compute_loss</span><span class="p">,</span>
    <span class="n">optimizer_fcnn</span><span class="p">,</span>
    <span class="n">nlocal_loader_train</span><span class="p">,</span>
    <span class="n">nlocal_loader_test</span><span class="p">,</span>
    <span class="n">n_epochs</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training completed in 107 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_loss_online</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_loss_online</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MSE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Epochs&#39;)
</pre></div>
</div>
<img alt="../_images/bd0060e0df1c0abe4a50d89cd347e4be2f5d97e1791d6ee28888efb3f5dd0a0f.png" src="../_images/bd0060e0df1c0abe4a50d89cd347e4be2f5d97e1791d6ee28888efb3f5dd0a0f.png" />
</div>
</div>
<p>The loss curve above shows that online model is training well, and parameters have been optimized in some sense. Let us check below how this online trained model compares against the offline trained model from the previous notebook.</p>
</div>
<div class="section" id="test-in-a-simulation-online-testing">
<h2>Test in a simulation: Online testing<a class="headerlink" href="#test-in-a-simulation-online-testing" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load in the previously trained non-local offline network.</span>
<span class="n">nonlocal_FCNN_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./networks/non_local_FCNN.pth&quot;</span><span class="p">)</span>

<span class="n">fcnn_offline_network</span> <span class="o">=</span> <span class="n">FCNN_nonlocal</span><span class="p">()</span>
<span class="n">fcnn_offline_network</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">nonlocal_FCNN_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The different GCM classes</span>
<span class="c1"># ---------------------------</span>


<span class="k">class</span> <span class="nc">GCM_without_parameterization</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GCM without parameterization</span>

<span class="sd">    Args:</span>
<span class="sd">        F: Forcing term</span>
<span class="sd">        time_stepping: Time stepping method</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">time_stepping</span><span class="o">=</span><span class="n">RK4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">F</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_stepping</span> <span class="o">=</span> <span class="n">time_stepping</span>

    <span class="k">def</span> <span class="nf">rhs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute right hand side of the the GCM equations&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">L96_eq1_xdot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">nt</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run GCM</span>

<span class="sd">        Args:</span>
<span class="sd">            X0: Initial conditions of X</span>
<span class="sd">            dt: Time increment</span>
<span class="sd">            nt: Number of forward steps to take</span>
<span class="sd">            param: Parameters of closure</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model output for all variables of X at each timestep</span>
<span class="sd">            along with the corresponding time units</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">time</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">dt</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nt</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nt</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">)))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
            <span class="n">X0</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="n">hist</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nt</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_stepping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rhs</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
            <span class="n">hist</span><span class="p">[</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">time</span><span class="p">[</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hist</span><span class="p">,</span> <span class="n">time</span>


<span class="k">class</span> <span class="nc">GCM_network</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;GCM with neural network parameterization</span>

<span class="sd">    Args:</span>
<span class="sd">        F: Forcing term</span>
<span class="sd">        network: Neural network</span>
<span class="sd">        time_stepping: Time stepping method</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">time_stepping</span><span class="o">=</span><span class="n">RK4</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">F</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_stepping</span> <span class="o">=</span> <span class="n">time_stepping</span>

    <span class="k">def</span> <span class="nf">rhs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute right hand side of the the GCM equations&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">linear1</span><span class="o">.</span><span class="n">in_features</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">X_torch</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Adding NN parameterization</span>
        <span class="k">return</span> <span class="n">L96_eq1_xdot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">F</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">X_torch</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X0</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">nt</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run GCM</span>

<span class="sd">        Args:</span>
<span class="sd">            X0: Initial conditions of X</span>
<span class="sd">            dt: Time increment</span>
<span class="sd">            nt: Number of forward steps to take</span>
<span class="sd">            param: Parameters of closure</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model output for all variables of X at each timestep</span>
<span class="sd">            along with the corresponding time units</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">time</span><span class="p">,</span> <span class="n">hist</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">dt</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nt</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nt</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">)))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span>
            <span class="n">X0</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="n">hist</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nt</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_stepping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rhs</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
            <span class="n">hist</span><span class="p">[</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">time</span><span class="p">[</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hist</span><span class="p">,</span> <span class="n">time</span>
</pre></div>
</div>
</div>
</div>
<p>Now let us pick a random point in the simulation as our initial condition, and compare if there is some drastic difference between offline and online parameterization that can be seen visually.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="mi">2100</span>
<span class="n">init_conditions</span> <span class="o">=</span> <span class="n">X_true</span><span class="p">[</span><span class="n">start</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">T_test</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">forcing</span> <span class="o">=</span> <span class="mi">18</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.01</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gcm_no_param</span> <span class="o">=</span> <span class="n">GCM_without_parameterization</span><span class="p">(</span><span class="n">forcing</span><span class="p">)</span>
<span class="n">X_no_param</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_no_param</span><span class="p">(</span><span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate with nonlocal offline FCNN</span>
<span class="n">gcm_nonlocal_offline_net</span> <span class="o">=</span> <span class="n">GCM_network</span><span class="p">(</span><span class="n">forcing</span><span class="p">,</span> <span class="n">fcnn_offline_network</span><span class="p">)</span>
<span class="n">Xnn_nonlocal_offline</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_nonlocal_offline_net</span><span class="p">(</span>
    <span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">),</span> <span class="n">fcnn_offline_network</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate with nonlocal offline FCNN</span>
<span class="n">gcm_nonlocal_online_net</span> <span class="o">=</span> <span class="n">GCM_network</span><span class="p">(</span><span class="n">forcing</span><span class="p">,</span> <span class="n">fcnn_online_network</span><span class="p">)</span>
<span class="n">Xnn_nonlocal_online</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_nonlocal_online_net</span><span class="p">(</span>
    <span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">),</span> <span class="n">fcnn_online_network</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">time_i</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="n">time_i</span><span class="p">],</span> <span class="n">X_true</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">time_i</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Full L96&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="n">time_i</span><span class="p">],</span> <span class="n">X_no_param</span><span class="p">[:</span><span class="n">time_i</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;No parameterization&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="n">time_i</span><span class="p">],</span> <span class="n">Xnn_nonlocal_offline</span><span class="p">[:</span><span class="n">time_i</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Offline parameterization&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="n">time_i</span><span class="p">],</span> <span class="n">Xnn_nonlocal_online</span><span class="p">[:</span><span class="n">time_i</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Online parameterization&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span>
    <span class="mi">0</span><span class="p">,</span>
    <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">t</span><span class="p">[</span><span class="n">Tstep_train</span><span class="p">],</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;time range of online training&quot;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/91ad94acaed53c78536427a711bdf743c2f06080c31d0844043de57b9534e791.png" src="../_images/91ad94acaed53c78536427a711bdf743c2f06080c31d0844043de57b9534e791.png" />
</div>
</div>
<p>The above plot shows that both offline and online trained models perform much better than the simulation without any parameterization. However, it is unclear if there is any signficant gain in the online case. To be more precise, we compare the different cases below over many simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">err_noparam</span><span class="p">,</span> <span class="n">err_offline</span><span class="p">,</span> <span class="n">err_online</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">T_test</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">init_conditions_i</span> <span class="o">=</span> <span class="n">X_true</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Evaluate with no parameterization</span>
    <span class="n">gcm_no_param</span> <span class="o">=</span> <span class="n">GCM_without_parameterization</span><span class="p">(</span><span class="n">forcing</span><span class="p">)</span>
    <span class="n">X_no_param</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_no_param</span><span class="p">(</span><span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>

    <span class="c1"># Evaluate with local FCNN</span>
    <span class="n">gcm_nonlocal_offline_net</span> <span class="o">=</span> <span class="n">GCM_network</span><span class="p">(</span><span class="n">forcing</span><span class="p">,</span> <span class="n">fcnn_offline_network</span><span class="p">)</span>
    <span class="n">Xnn_nonlocal_offline</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_nonlocal_offline_net</span><span class="p">(</span>
        <span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">),</span> <span class="n">fcnn_offline_network</span>
    <span class="p">)</span>

    <span class="c1"># Evaluate with nonlocal FCNN</span>
    <span class="n">gcm_nonlocal_online_net</span> <span class="o">=</span> <span class="n">GCM_network</span><span class="p">(</span><span class="n">forcing</span><span class="p">,</span> <span class="n">fcnn_online_network</span><span class="p">)</span>
    <span class="n">Xnn_nonlocal_online</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">gcm_nonlocal_online_net</span><span class="p">(</span>
        <span class="n">init_conditions</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_test</span> <span class="o">/</span> <span class="n">dt</span><span class="p">),</span> <span class="n">fcnn_online_network</span>
    <span class="p">)</span>

    <span class="n">err_noparam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X_true</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">T_test</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_no_param</span><span class="p">))</span>
    <span class="p">)</span>

    <span class="n">err_offline</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X_true</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">T_test</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xnn_nonlocal_offline</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="n">err_online</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X_true</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">T_test</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Xnn_nonlocal_online</span><span class="p">))</span>
    <span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of errors for no parameterization: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">err_noparam</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of errors for offline parameterization: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">err_offline</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sum of errors for online parameterization: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">err_online</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sum of errors for no parameterization: 526830.43
Sum of errors for offline parameterization: 432909.76
Sum of errors for online parameterization: 428407.07
</pre></div>
</div>
</div>
</div>
<p>This assessment shows that the online parameterization performs about the same as offline parameterzation. However, atleast for the L96 model the gains (if any), which come at the cost of signfiant complexity, are not drastic.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>In this notebook we described how online training differs from offline training, and provided an example of how online training can be done for the L96 model. While for the L96 model the online training procedure did not produce significant improvements, the gains for other models may be much greater. If interested, you may look at this <a class="reference external" href="https://raspstephan.github.io/blog/lorenz-96-is-too-easy/">blog post</a> arguing that L96 might be too simple a test case, which is why different training procedures do not result in very significant differences.</p>
<p>In the next few notebooks we show a few tricks to potentially improve performance of neural networks, how to interpret neural networks, and how physics constraints can be added in their architecture.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="L96_online_implement_NN.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Using Neural Networks for L96 Parameterization: Online Testing</p>
      </div>
    </a>
    <a class="right-next"
       href="Improving_Neural_networks.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Improving Performance of Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#outline">Outline:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#online-vs-offline-training">Online vs offline training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-ground-truth-dataset-from-the-real-world">Generate the Ground Truth Dataset from the <em>Real World</em></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-differentiable-1-time-scale-l96-model">Create a differentiable 1 time-scale L96 model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-a-neural-network-for-the-parameterization">Define a Neural Network for the parameterization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function-and-optimizer-for-online-training">Loss function and optimizer for online training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-in-a-simulation-online-testing">Test in a simulation: Online testing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The M<sup>2</sup>LInES Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024 Dhruv Balwada, Ryan Abernathey, Shantanu Acharya, et al. — License: MIT for code, CC-BY for text and figures.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>